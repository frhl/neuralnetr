% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ReLU.R
\name{ReLU}
\alias{ReLU}
\title{Rectified linear outout activation}
\description{
Each activation module has a forward method that
takes in a batch of pre-activations Z and returns a batch of
activations A.

Each activation module has a backward method that takes in dLdA and
returns dLdZ, with the exception of SoftMax, where we assume dLdZ is
passed in.
}
\seealso{
Other activation: 
\code{\link{Sigmoid}},
\code{\link{SoftMax}},
\code{\link{Tanh}}
}
\concept{activation}
\section{Super class}{
\code{\link[neuralnetr:ClassModule]{neuralnetr::ClassModule}} -> \code{ReLU}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{A}}{the activation vector}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-forward}{\code{ReLU$forward()}}
\item \href{#method-backward}{\code{ReLU$backward()}}
\item \href{#method-clone}{\code{ReLU$clone()}}
}
}
\if{html}{
\out{<details open ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="neuralnetr" data-topic="ClassModule" data-id="sgd_step">}\href{../../neuralnetr/html/ClassModule.html#method-sgd_step}{\code{neuralnetr::ClassModule$sgd_step()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-forward"></a>}}
\subsection{Method \code{forward()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ReLU$forward(Z)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{Z}}{a vector of pre-activations}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
a vector of activations.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-backward"></a>}}
\subsection{Method \code{backward()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ReLU$backward(dLdA)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dLdA}}{vector of gradients.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
a vector gradeints.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ReLU$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
